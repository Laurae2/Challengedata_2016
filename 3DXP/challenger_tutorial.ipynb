{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post recommendation from implicit feedback\n",
    "====\n",
    "\n",
    "<i>Challenge Data 2016.</i>\n",
    "<b>N.B. the code uses Python 2 </b>\n",
    "\n",
    "Based on the history of user \"likes\" over posts, the goal of the challenge is to recommend new posts that a user might like.\n",
    "\n",
    "The dataset is split between four matrices: `input_train`, `output_train` and `input_test`, `output_test`.\n",
    "\n",
    "There are three phases: \n",
    "\n",
    "1) You design and tune your algorithm by alternating between the two:\n",
    "\n",
    "    a. You train your algorithm on `input_train`, and predict scores `train_scores`.\n",
    "    b. You evaluate `train_scores` against the ground truth `output_train`\n",
    "    \n",
    "2) One, you have good parameters, you export recommendations for the challenge:\n",
    "\n",
    "    a. You train your algorithm on `input_test`, and predict scores `test_scores`.\n",
    "    b. You call `binarize`, which binarizes your scores and removes recommendations for items in the training set, then you export the resulting `test_predict` in a file `test_pred.csv` and submit it to the ChallengeData platform.\n",
    "    \n",
    "3) We (organisers of the challenge) will evaluate `test_predict` by computing its precision@5 with respect to the (hidden) `output_test`\n",
    "\n",
    "In this tutorial we show how to do phases 1) and 2) using a simple algorithm, the popularity baseline, which recommends the 5 most popular items not already liked to each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The evaluation strategy is the following. For each user:\n",
    "- All likes are split between a input and a output set, called `input` and `output` in this notebook)\n",
    "- The algorithm assigns scores of preference to all items. In this notebook the scores predicted by the popularity baseline are called `pop_scores`.\n",
    "- For each user validation data is given.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data\n",
    "-----\n",
    "\n",
    "Before running the following, ensure that the data files are next to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "reload (helpers)\n",
    "from helpers import load_csr, save_csr, print_metrics, binarize\n",
    "\n",
    "# Load scipy.sparse.csr_matrix data\n",
    "input_train = load_csr('input_train.csv')\n",
    "output_train = load_csr('output_train.csv')\n",
    "input_test = load_csr('input_test.csv')\n",
    "\n",
    "# Densify to np.array for convenience\n",
    "input_train_dense = input_train.toarray()\n",
    "output_train_dense = output_train.toarray()\n",
    "input_test_dense = input_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity baseline\n",
    "----\n",
    "\n",
    "The simplest algorithm is sort the items by popularity, and to recommend for each user the top-5 items that he has not seen already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def popularity_baseline(input_dense):\n",
    "    # Get item popularities\n",
    "    per_item = input_dense.sum(axis=0)\n",
    "\n",
    "    # Compute the (same) scores for each user\n",
    "    pop_scores = np.outer(np.ones(input_dense.shape[0]), per_item)\n",
    "    \n",
    "    return pop_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your algorithm on `input_train`\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores = popularity_baseline(input_train_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with Precision@5 on `output_train`\n",
    "----\n",
    "\n",
    "Now we compute the precision@5 score using the `print_metrics` routine, which for each user will ignore the scores of items already present in `input_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape (1065L, 905L)\n",
      "K=5\n",
      "Metrics ['precision@k', 'recall@k', 'f1@k']\n",
      "Train [ 0.02835681  0.04693821  0.03012455]\n",
      "Test [ 0.02929577  0.04659194  0.03232149]\n",
      "Shapes. Train (1065L, 3L) Test (1065L, 3L)\n",
      "\n",
      "Test precision 0.0292957746479\n"
     ]
    }
   ],
   "source": [
    "input_scores, output_scores = print_metrics(train_scores,\n",
    "                                            input_train,\n",
    "                                            output_train,\n",
    "                                            k=5)\n",
    "\n",
    "test_precision = output_scores[0]\n",
    "print '\\nTest precision', test_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Here you should do some tuning)\n",
    "----\n",
    "\n",
    "In our simple example the baseline popularity method has no parameters to tune, but typically you would choose your parameters by evaluating your predictions against `output_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your algorithm on `input_test`\n",
    "----\n",
    "\n",
    "Now we predict the results for the final evaluation, by training on `input_test`.\n",
    "Then we export the scores, for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_scores = popularity_baseline(input_test_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nls2\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\scipy\\sparse\\compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "test_predict = binarize(test_scores, input_test, k=5)\n",
    "\n",
    "# Export the scores\n",
    "save_csr('test_pred', test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
